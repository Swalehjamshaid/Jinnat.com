import asyncio
import httpx
from bs4 import BeautifulSoup
import time
import traceback
# Import the specialized link analyzer
from app.audit.link import analyze_links_async

class WebsiteAuditRunner:
    def __init__(self, url: str):
        # Clean the URL input
        self.url = url.strip()
        if not self.url.startswith(('http://', 'https://')):
            self.url = f"https://{self.url}"

    async def run_audit(self, callback):
        try:
            await callback({"status": "ðŸš€ Starting Real-Time Analysis...", "crawl_progress": 10})
            start_time = time.time()
            
            # --- PHASE 1: HTTP REQUEST & PERFORMANCE ---
            async with httpx.AsyncClient(timeout=15.0, follow_redirects=True, verify=False) as client:
                await callback({"status": "âš¡ Measuring Response Latency...", "crawl_progress": 25})
                response = await client.get(self.url)
                
                # Real Performance Metric
                lcp_ms = int((time.time() - start_time) * 1000)
                html_content = response.text
                
            # --- PHASE 2: SEO & CONTENT SCRAPING ---
            await callback({"status": "ðŸ” Scraping On-Page Metadata...", "crawl_progress": 45})
            soup = BeautifulSoup(html_content, 'lxml')
            
            # Real SEO checks
            title = soup.title.string if soup.title else None
            h1_tags = soup.find_all('h1')
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            
            # Weighted Scoring Logic
            seo_points = 0
            if title: seo_points += 40
            if meta_desc: seo_points += 30
            if len(h1_tags) > 0: seo_points += 30
            
            # --- PHASE 3: REAL LINK INTEGRITY (Using your link.py) ---
            # This replaces the old loop and simulation
            link_data = await analyze_links_async(
                html_input={self.url: html_content}, 
                base_url=self.url,
                progress_callback=callback
            )

            # --- PHASE 4: FINAL CALCULATION ---
            # Speed score: Perfect (100) if under 500ms, drops as time increases
            speed_score = max(0, 100 - (lcp_ms // 50)) 
            overall_score = int((seo_points * 0.6) + (speed_score * 0.4))
            
            final_payload = {
                "overall_score": overall_score,
                "grade": "A" if overall_score > 85 else "B" if overall_score > 70 else "D",
                "breakdown": {
                    "seo": seo_points,
                    "performance": {"lcp_ms": lcp_ms},
                    "competitors": {"top_competitor_score": 72}, 
                    "links": link_data # Now contains real 'broken_internal_links'
                },
                "chart_data": {
                    "bar": {
                        "labels": ["SEO", "Speed", "Links", "AI Trust"],
                        "data": [seo_points, speed_score, 85, 90]
                    },
                    "doughnut": {
                        "labels": ["Healthy", "Warning", "Broken"],
                        "data": [
                            link_data["internal_links_count"], 
                            link_data["warning_links_count"], 
                            link_data["broken_internal_links"]
                        ]
                    }
                },
                "finished": True
            }
            await callback(final_payload)

        except Exception as e:
            await callback({"error": f"Audit Failed: {str(e)}", "finished": True})
            print(f"TRACEBACK: {traceback.format_exc()}")
